# Procon/src/create_lstm_dataset.py

import numpy as np
import os
from pathlib import Path
from sklearn.preprocessing import StandardScaler

# --- å®šæ•°å®šç¾© ---
# NTU RGB+Dã®é–¢ç¯€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
# æŒ‡æ®ã§é‡è¦ãã†ãªé–¢ç¯€ã«çµã‚‹ (å³æ‰‹ã€å·¦æ‰‹ã€å³è‚˜ã€å·¦è‚˜)
# (4é–¢ç¯€ x 3åº§æ¨™ = 12ç‰¹å¾´é‡/ãƒ•ãƒ¬ãƒ¼ãƒ )
KEY_JOINTS_INDICES = [11, 7, 10, 6] 

# 1ã¤ã®å‹•ç”»ã®æœ€å¤§ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ï¼ˆã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ï¼‰
# ã“ã‚Œã‚ˆã‚Šé•·ã„å‹•ç”»ã¯åˆ‡ã‚Šæ¨ã¦ã€çŸ­ã„å‹•ç”»ã¯ã‚¼ãƒ­ã§åŸ‹ã‚ã‚‹
MAX_TIMESTEPS = 150

# --- ãƒ‘ã‚¹è¨­å®š ---
script_path = Path(__file__).resolve()
project_root = script_path.parent.parent
skeleton_folder = project_root / 'data' / 'skeletons'
# å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã¯Numpyå°‚ç”¨å½¢å¼(.npy)ã§ä¿å­˜ï¼ˆCSVã‚ˆã‚Šé«˜é€Ÿã§å¤§å®¹é‡å‘ãï¼‰
output_data_path = project_root / 'data' / 'lstm_data.npy'
output_labels_path = project_root / 'data' / 'lstm_labels.npy'
output_scaler_path = project_root / 'data' / 'lstm_scaler.gz' # joblibã¯ãã®ã¾ã¾ä½¿ãˆã‚‹

# --- é–¢æ•°å®šç¾© ---
# (parse_ntu_skeletoné–¢æ•°ã¯å‰å›ã¨åŒã˜ãªã®ã§ã“ã“ã«å«ã‚ã¾ã™)
def parse_ntu_skeleton(filepath):
    # ... (å‰å›ã®å¿œç­”ã¨åŒã˜ã‚³ãƒ¼ãƒ‰) ...
    try:
        with open(filepath, 'r') as f: lines = f.readlines()
        frame_count = int(lines[0])
        all_frames_data, line_idx = [], 1
        for _ in range(frame_count):
            if line_idx >= len(lines): break
            body_count = int(lines[line_idx]); line_idx += 1
            frame_data = np.zeros((25, 3))
            if body_count > 0:
                line_idx += 1
                joint_count = int(lines[line_idx]); line_idx += 1
                for j in range(joint_count):
                    joint_info = lines[line_idx].split()
                    frame_data[j] = [float(coord) for coord in joint_info[0:3]]
                    line_idx += 1
                if body_count > 1: line_idx += (body_count - 1) * (1 + 1 + joint_count)
            all_frames_data.append(frame_data)
        return np.array(all_frames_data)
    except (IOError, ValueError): return None

# --- ãƒ¡ã‚¤ãƒ³å‡¦ç† ---
def main():
    skeleton_files = [f for f in os.listdir(skeleton_folder) if f.endswith('.skeleton')]
    
    all_sequences = []
    all_labels = []

    for i, filename in enumerate(skeleton_files):
        print(f"å‡¦ç†ä¸­ ({i+1}/{len(skeleton_files)}): {filename}")
        filepath = skeleton_folder / filename
        
        skeleton_data = parse_ntu_skeleton(filepath)
        if skeleton_data is None or len(skeleton_data) == 0: continue

        # 1. é‡è¦ãªé–¢ç¯€ã®ãƒ‡ãƒ¼ã‚¿ã ã‘ã‚’æŠ½å‡º
        key_joints_data = skeleton_data[:, KEY_JOINTS_INDICES, :]
        # (ãƒ•ãƒ¬ãƒ¼ãƒ æ•°, 4é–¢ç¯€, 3åº§æ¨™) -> (ãƒ•ãƒ¬ãƒ¼ãƒ æ•°, 12ç‰¹å¾´é‡) ã«å¤‰å½¢
        sequence = key_joints_data.reshape(len(key_joints_data), -1)

        # 2. ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°/ãƒˆãƒ©ãƒ³ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§é•·ã•ã‚’MAX_TIMESTEPSã«æƒãˆã‚‹
        padded_sequence = np.zeros((MAX_TIMESTEPS, sequence.shape[1]))
        length = min(len(sequence), MAX_TIMESTEPS)
        padded_sequence[:length, :] = sequence[:length, :]
        
        all_sequences.append(padded_sequence)

        # 3. ãƒ©ãƒ™ãƒ«ã®ä½œæˆ (ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ID - 1)
        try:
            label = int(filename.split('A')[1][:3]) - 1
            all_labels.append(label)
        except (IndexError, ValueError):
            del all_sequences[-1] # ãƒ©ãƒ™ãƒ«ãŒä½œã‚Œãªã‹ã£ãŸãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤

    X = np.array(all_sequences)
    y = np.array(all_labels)

    # 4. ãƒ‡ãƒ¼ã‚¿å…¨ä½“ã‚’ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
    # (ã‚µãƒ³ãƒ—ãƒ«æ•°, ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—, ç‰¹å¾´é‡) -> (ã‚µãƒ³ãƒ—ãƒ«æ•°*ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—, ç‰¹å¾´é‡)
    X_reshaped = X.reshape(-1, X.shape[2])
    scaler = StandardScaler()
    X_scaled_reshaped = scaler.fit_transform(X_reshaped)
    # å…ƒã®3æ¬¡å…ƒå½¢çŠ¶ã«æˆ»ã™
    X_scaled = X_scaled_reshaped.reshape(X.shape)

    # 5. ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    np.save(output_data_path, X_scaled)
    np.save(output_labels_path, y)
    import joblib
    joblib.dump(scaler, output_scaler_path)

    print("-" * 30)
    print(f"ğŸ‰ LSTMç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä½œæˆãŒå®Œäº†ï¼")
    print(f"ãƒ‡ãƒ¼ã‚¿ä¿å­˜å…ˆ: {output_data_path}")
    print(f"ãƒ©ãƒ™ãƒ«ä¿å­˜å…ˆ: {output_labels_path}")

if __name__ == '__main__':
    main()